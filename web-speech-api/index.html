<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Web Speech API Demo</title>
    <style>
      /* No CSS for styling, but a minimal style for button size to avoid layout shift */
      button {
          width: 150px; /* Fixed width */
          height: 50px; /* Fixed height */
          font-size: 16px;
          display: block; /* To center it easily if needed, though not strictly styling */
          margin: 20px auto; /* Just to center it a bit */
      }
      #output {
          margin-top: 20px;
          padding: 10px;
          border: 1px solid #ccc;
          min-height: 50px; /* Minimal height to avoid shift when text appears */
          white-space: pre-wrap; /* To preserve line breaks */
          word-wrap: break-word; /* To break long words */
      }
      #status {
          margin-top: 10px;
          font-weight: bold;
          color: #333;
      }
    </style>
  </head>
  <body>
    <h1>Web Speech API Demo</h1>

    <p>Press and hold the button to speak. Release to stop and hear the synthesized voice.</p>

    <button id="speakButton">Hold to Speak</button>

    <div id="status">Status: Ready</div>
    <div id="output"></div>

    <script>
      const speakButton = document.getElementById("speakButton");
      const outputDiv = document.getElementById("output");
      const statusDiv = document.getElementById("status");

      let recognition;
      let synth;
      let utterance;
      let isRecognizing = false;
      let finalTranscript = "";

      // Initialize SpeechRecognition
      if ("webkitSpeechRecognition" in window) {
        recognition = new webkitSpeechRecognition();
        recognition.continuous = true; // Continuous recognition
        recognition.interimResults = true; // Get interim results
        recognition.lang = "en-US";

        recognition.onstart = () => {
          isRecognizing = true;
          statusDiv.textContent = "Status: Listening...";
          speakButton.textContent = "Release to Stop";
          outputDiv.textContent = ""; // Clear previous output
          finalTranscript = "";
        };

        recognition.onresult = (event) => {
          let interimTranscript = "";
          for (let i = event.resultIndex; i < event.results.length; ++i) {
            if (event.results[i].isFinal) {
              finalTranscript += event.results[i][0].transcript;
            } else {
              interimTranscript += event.results[i][0].transcript;
            }
          }
          outputDiv.textContent = finalTranscript + interimTranscript;
        };

        recognition.onerror = (event) => {
          isRecognizing = false;
          statusDiv.textContent = `Status: Error - ${event.error}`;
          speakButton.textContent = "Hold to Speak";
          console.error("Speech recognition error:", event.error);
        };

        recognition.onend = () => {
          isRecognizing = false;
          statusDiv.textContent = "Status: Processing...";
          speakButton.textContent = "Hold to Speak";

          if (finalTranscript.trim().length > 0) {
            outputDiv.textContent = finalTranscript; // Display final transcript
            synthesizeSpeech(finalTranscript);
          } else {
            statusDiv.textContent = "Status: No speech detected.";
          }
        };
      } else {
        statusDiv.textContent = "Status: Web Speech API is not supported in this browser.";
        speakButton.disabled = true;
      }

      // Initialize SpeechSynthesis
      if ("speechSynthesis" in window) {
        synth = window.speechSynthesis;
        utterance = new SpeechSynthesisUtterance();
        utterance.lang = "en-US";
        utterance.onend = () => {
          statusDiv.textContent = "Status: Ready";
        };
        utterance.onerror = (event) => {
          statusDiv.textContent = `Status: Speech synthesis error - ${event.error}`;
          console.error("Speech synthesis error:", event);
        };
      } else {
        statusDiv.textContent = "Status: Web Speech Synthesis API is not supported in this browser.";
      }

      function synthesizeSpeech(text) {
        if (synth && text.trim().length > 0) {
          statusDiv.textContent = "Status: Speaking...";
          utterance.text = text;
          synth.speak(utterance);
        }
      }

      speakButton.addEventListener("mousedown", () => {
        if (recognition && !isRecognizing) {
          try {
            recognition.start();
          } catch (e) {
            console.error("Error starting recognition:", e);
            statusDiv.textContent = `Status: Error starting recognition - ${e.message}`;
          }
        }
      });

      speakButton.addEventListener("mouseup", () => {
        if (recognition && isRecognizing) {
          recognition.stop();
        }
      });

      // For touch devices
      speakButton.addEventListener("touchstart", (e) => {
        e.preventDefault(); // Prevent default touch behavior like scrolling
        if (recognition && !isRecognizing) {
          try {
            recognition.start();
          } catch (e) {
            console.error("Error starting recognition:", e);
            statusDiv.textContent = `Status: Error starting recognition - ${e.message}`;
          }
        }
      });

      speakButton.addEventListener("touchend", (e) => {
        e.preventDefault(); // Prevent default touch behavior
        if (recognition && isRecognizing) {
          recognition.stop();
        }
      });
    </script>
  </body>
</html>
